{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import re\n",
    "\n",
    "# Functions \n",
    "\n",
    "def add_feature(X, feature_to_add):\n",
    "    \"\"\"\n",
    "    Returns sparse feature matrix with added feature.\n",
    "    feature_to_add can also be a list of features.\n",
    "    \"\"\"\n",
    "    from scipy.sparse import csr_matrix, hstack\n",
    "    return hstack([X, csr_matrix(feature_to_add).T], 'csr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing and splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_data = pd.read_csv('spam.csv')\n",
    "spam_data['target'] = np.where(spam_data['target']=='spam',1,0)\n",
    "spam_data.head(10)\n",
    "X_train, X_test, y_train, y_test = train_test_split(spam_data['text'], spam_data['target'],random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.41% of the texts are SPAM texts.\n",
      "The longest word in the data is : com1win150ppmx3age16subscription\n",
      "\n",
      "The avg lenght of documents for spam documents: 138.87\n",
      "The avg lenght of documents for not spam documents: 71.02\n",
      "\n",
      "The average number of digits per document for  spam: 15.76\n",
      "The average number of digits per document for not spam : 0.30\n",
      "\n",
      "The average number of non-word characters per document for spam: 29.04\n",
      "The average number of non-word characters per document for not spam : 17.29\n",
      "\n",
      "The 20 words with SMALLEST tfidf :\n",
      "aaniye          0.074475\n",
      "athletic        0.074475\n",
      "chef            0.074475\n",
      "companion       0.074475\n",
      "courageous      0.074475\n",
      "dependable      0.074475\n",
      "determined      0.074475\n",
      "exterminator    0.074475\n",
      "healer          0.074475\n",
      "listener        0.074475\n",
      "organizer       0.074475\n",
      "pest            0.074475\n",
      "psychiatrist    0.074475\n",
      "psychologist    0.074475\n",
      "pudunga         0.074475\n",
      "stylist         0.074475\n",
      "sympathetic     0.074475\n",
      "venaam          0.074475\n",
      "diwali          0.091250\n",
      "mornings        0.091250\n",
      "dtype: float64\n",
      "\n",
      "The 20 words with LARGEST tfidf : \n",
      "645         1.000000\n",
      "anything    1.000000\n",
      "anytime     1.000000\n",
      "beerage     1.000000\n",
      "done        1.000000\n",
      "er          1.000000\n",
      "havent      1.000000\n",
      "home        1.000000\n",
      "lei         1.000000\n",
      "nite        1.000000\n",
      "ok          1.000000\n",
      "okie        1.000000\n",
      "thank       1.000000\n",
      "thanx       1.000000\n",
      "too         1.000000\n",
      "where       1.000000\n",
      "yup         1.000000\n",
      "tick        0.980166\n",
      "blank       0.932702\n",
      "same        0.932467\n",
      "dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#What percentage of the documents in spam_data are spam?\n",
    "ratio_spam=(len(spam_data[spam_data['target']==1])*100)/spam_data.shape[0]\n",
    "print('{:3.2f}% of the texts are SPAM texts.'.format(ratio_spam))\n",
    "\n",
    "#What is the longest token in the vocabulary?\n",
    "vectorizer = CountVectorizer() #CountVectorizer : Convert a collection of text documents to a matrix of token counts\n",
    "X = vectorizer.fit_transform(X_train)\n",
    "my_list=[(len(w),w) for w in vectorizer.get_feature_names()]    \n",
    "print(f'The longest word in the data is : {max(my_list)[1]}\\n')\n",
    "\n",
    "#What is the average length of documents (number of characters) for not spam and spam documents?\n",
    "df_spam=spam_data.copy()\n",
    "df_spam['lenght']=df_spam['text'].str.len()\n",
    "avgspam=df_spam[df_spam['target']==1].lenght.mean()\n",
    "avgnspam=df_spam[df_spam['target']==0].lenght.mean()\n",
    "print('The avg lenght of documents for spam documents: {:.2f}'.format(avgspam))\n",
    "print('The avg lenght of documents for not spam documents: {:.2f}\\n'.format(avgnspam))\n",
    "\n",
    "#What is the average number of digits per document for not spam and spam documents?\n",
    "\n",
    "df_spam1=spam_data.copy()\n",
    "#df_spam1['digits']=df_spam1['text'].str.findall(r'\\d').str.len()\n",
    "df_spam1['digits']=df_spam1['text'].str.findall('\\d').map(lambda x : len(x))\n",
    "avgdigspam=df_spam1[df_spam1.target==1].digits.mean()\n",
    "avgdignspam=df_spam1[df_spam1.target==0].digits.mean()\n",
    "print('The average number of digits per document for  spam: {:.2f}'.format(avgdigspam))\n",
    "print('The average number of digits per document for not spam : {:.2f}\\n'.format(avgdignspam))\n",
    "\n",
    "#What is the average number of non-word characters per document for not spam and spam documents?\n",
    "df_spam2 = spam_data.copy()\n",
    "#df_spam2['nn_word']=df_spam2['text'].str.findall(r'[^a-zA-Z0-9_]').str.len()\n",
    "df_spam2['nn_word']=df_spam2['text'].str.findall(r'\\W').str.len()\n",
    "avgnwspam=df_spam2[df_spam2.target==1]['nn_word'].mean()\n",
    "avgnwnspam=df_spam2[df_spam2.target==0]['nn_word'].mean()\n",
    "print('The average number of non-word characters per document for spam: {:.2f}'.format(avgnwspam))\n",
    "print('The average number of non-word characters per document for not spam : {:.2f}\\n'.format(avgnwnspam))\n",
    "\n",
    "# What 20 features have the smallest tf-idf and what 20 have the largest tf-idf?\n",
    "vec = TfidfVectorizer().fit(X_train) #Convert a collection of text documents to a matrix of token counts (scale down the impact of tokens that occur very frequently)\n",
    "X_trainVectf = vec.transform(X_train)\n",
    "feature_names = np.array(vec.get_feature_names())\n",
    "sorted_tfidf_index=X_trainVectf.toarray().max(0).argsort()\n",
    "smallest_tf_idfs=pd.Series(np.sort(X_trainVectf.max(0).toarray()[0])[0:20],index=feature_names[sorted_tfidf_index[0:20]])\n",
    "smallest_tf_idfs=smallest_tf_idfs.sort_index().sort_values(kind='mergesort')\n",
    "largest_tf_idfs=pd.Series(np.sort(X_trainVectf.max(0).toarray()[0])[-21:-1],index=feature_names[sorted_tfidf_index[-21:-1]])\n",
    "largest_tf_idfs=largest_tf_idfs.sort_index(ascending=False).sort_values(ascending=False,kind='mergesort')\n",
    "print('The 20 words with SMALLEST tfidf :\\n{}\\n'.format(smallest_tf_idfs))\n",
    "print('The 20 words with LARGEST tfidf : \\n{}\\n\\n'.format(largest_tf_idfs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score using CountVectorizer and Multinomial Naive Bayes is 0.97.\n",
      "\n",
      "The AUC score using TfidfVectorizer and Multinomial Naive Bayes is 0.94.\n",
      "\n",
      "The AUC score using TfidfVectorizer, adding one feature and SVM is 0.97.\n",
      "\n",
      "The AUC score using TfidfVectorizer, adding two features and Logistic Regression is 0.97.\n",
      "\n",
      "The AUC score using CountVectorizer, adding three features and Logistic Regression is 0.97\n",
      "   => The 10 largest coefficients from this model : ['digit_count' 'ia' ' r' 'xt' 'ne' 'co' ' ba' ' x' 'ian ' '46']\n",
      "   => The 10 smallest coefficients from this model :[' i' 'ca' '..' '. ' 'pe' ' go' ' m' 'if' 'us' 'go']\n"
     ]
    }
   ],
   "source": [
    "# Modelling with CountVectorizer and MultinomialNB \n",
    "vec = CountVectorizer(min_df=3)\n",
    "X_trainVectorized = vec.fit_transform(X_train)\n",
    "clfMNB = MultinomialNB(alpha=0.1)\n",
    "clfMNB.fit(X_trainVectorized, y_train)\n",
    "y_predtest= clfMNB.predict(vec.transform(X_test))\n",
    "score1 =roc_auc_score (y_test,y_predtest)\n",
    "print('The AUC score using CountVectorizer and Multinomial Naive Bayes is {:.2f}.\\n'.format(score1))\n",
    "\n",
    "# Modelling with TfidfVectorizer and MultinomialNB \n",
    "\n",
    "vec=TfidfVectorizer(min_df=3).fit(X_train)\n",
    "X_trainVectTf = vec.transform(X_train)\n",
    "ClfMNB=MultinomialNB(alpha=0.1)\n",
    "ClfMNB.fit(X_trainVectTf,y_train)\n",
    "ypred=ClfMNB.predict(vec.transform(X_test))\n",
    "score2=roc_auc_score(y_test,ypred)\n",
    "print('The AUC score using TfidfVectorizer and Multinomial Naive Bayes is {:.2f}.\\n'.format(score2))\n",
    "\n",
    "# Modelling with TfidfVectorizer,adding one feature (lenght of document) and SVM  \n",
    "\n",
    "vec=TfidfVectorizer(min_df=5).fit(X_train)\n",
    "X_traintransformed=vec.transform(X_train)\n",
    "X_traintrans_add=add_feature(X_traintransformed,X_train.str.len() )\n",
    "ClfSVC=SVC(C=10000)\n",
    "ClfSVC.fit(X_traintrans_add,y_train)\n",
    "Xtesttransformedadd=add_feature(vec.transform(X_test),X_test.str.len() )\n",
    "ypred= ClfSVC.predict(Xtesttransformedadd) \n",
    "score3=roc_auc_score(y_test,ypred)\n",
    "print('The AUC score using TfidfVectorizer, adding one feature and SVM is {:.2f}.\\n'.format(score3))\n",
    "\n",
    "# Modelling with TfidfVectorizer,adding 2 features (lenght of document & nbr digits per document) and LogisticRegression \n",
    "vec=TfidfVectorizer(min_df=5, ngram_range=(1,3)).fit(X_train)\n",
    "Xtraintrans=vec.transform(X_train)\n",
    "Xtraintrans_add1=add_feature(Xtraintrans,X_train.str.len())\n",
    "Xtraintrans_add2=add_feature(Xtraintrans_add1, X_train.str.findall(r'\\d').str.len())\n",
    "\n",
    "ClfLR=LogisticRegression(C=100,max_iter=1000)\n",
    "ClfLR.fit(Xtraintrans_add2,y_train)\n",
    "Xtesttrans=vec.transform(X_test)\n",
    "Xtesttrans_add1=add_feature(Xtesttrans,X_test.str.len())\n",
    "Xtesttrans_add2=add_feature(Xtesttrans_add1, X_test.str.findall(r'\\d').str.len())\n",
    "ypred=ClfLR.predict(Xtesttrans_add2)\n",
    "score4=roc_auc_score(y_test,ypred)\n",
    "print('The AUC score using TfidfVectorizer, adding two features and Logistic Regression is {:.2f}.\\n'.format(score4))\n",
    "\n",
    "# Modelling with CountVectorizer,adding 3 features and LogisticRegression \n",
    "\n",
    "vect=CountVectorizer(min_df=5,ngram_range=(2,5),analyzer='char_wb').fit(X_train)\n",
    "Xtraintrans=vect.transform(X_train)\n",
    "Xtesttrans=vect.transform(X_test)\n",
    "\n",
    "Xtraintrans_add1=add_feature(Xtraintrans,X_train.str.len())\n",
    "Xtraintrans_add2=add_feature(Xtraintrans_add1, X_train.str.findall(r'\\d').str.len())\n",
    "Xtraintrans_add3=add_feature(Xtraintrans_add2, X_train.str.findall(r'\\W').str.len())\n",
    "\n",
    "ClfLR=LogisticRegression(C=100,max_iter=1000).fit(Xtraintrans_add3,y_train)\n",
    "\n",
    "Xtesttrans_add1=add_feature(Xtesttrans,X_test.str.len(),)\n",
    "Xtesttrans_add2=add_feature(Xtesttrans_add1, X_test.str.findall(r'\\d').str.len())\n",
    "Xtesttrans_add3=add_feature(Xtesttrans_add2, X_test.str.findall(r'\\W').str.len())\n",
    "\n",
    "ypred=ClfLR.predict(Xtesttrans_add3)\n",
    "score=roc_auc_score(y_test,ypred)\n",
    "\n",
    "feature_names =np.array(vect.get_feature_names()+['length_of_doc', 'digit_count', 'non_word_char_count'])\n",
    "ClfLR.coef_.argsort()\n",
    "smallest_coef=feature_names[ClfLR.coef_[0].argsort()][0:10]\n",
    "largest_coef=feature_names[ClfLR.coef_[0].argsort()][:-11:-1]\n",
    "\n",
    "print('The AUC score using CountVectorizer, adding three features and Logistic Regression is {:.2f}'.format(score4))\n",
    "print('   => The 10 largest coefficients from this model : {}'.format(largest_coef))\n",
    "print('   => The 10 smallest coefficients from this model :{}'.format(smallest_coef))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
